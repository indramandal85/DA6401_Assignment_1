{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "892a6714-fd7b-4cbd-ac63-f272a4453a40",
      "metadata": {
        "id": "892a6714-fd7b-4cbd-ac63-f272a4453a40"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Regularisation:\n",
        "    def __init__(self, network, weight=0):\n",
        "        self.network = network\n",
        "        self.weight = weight\n",
        "\n",
        "class L2_regularisation(Regularisation):\n",
        "    def Apply_L2(self):\n",
        "        \"\"\"Returns L2 regularization loss for the given network.\"\"\"\n",
        "        L = len(self.network)\n",
        "        res = 0\n",
        "        for j in range(L):\n",
        "            if np.isnan(self.network[j].weight).any():\n",
        "                print(f\"Warning: NaN detected in network weights at layer {j}\")\n",
        "                return 0\n",
        "            res += 0.5 * np.sum(self.network[j].weight ** 2)\n",
        "        return res\n",
        "\n",
        "    def Apply_L2_grad(self, weight):\n",
        "        \"\"\"Returns L2 regularization gradient for the given weight matrix/tensor.\"\"\"\n",
        "        return 2 * weight\n",
        "\n",
        "class L1_regularisation(Regularisation):\n",
        "    def Apply_L1(self):\n",
        "        \"\"\"Returns L1 regularization loss for the given network.\"\"\"\n",
        "        L = len(self.network)\n",
        "        res = 0\n",
        "        for j in range(L):\n",
        "            if np.isnan(self.network[j].weight).any():\n",
        "                print(f\"Warning: NaN detected in network weights at layer {j}\")\n",
        "                return 0\n",
        "            res += (1 / 2) * np.sum(np.abs(self.network[j].weight))\n",
        "        return res\n",
        "\n",
        "    def Apply_L1_grad(self, weight):\n",
        "        \"\"\"Returns L1 regularization gradient for the given weight matrix/tensor.\"\"\"\n",
        "        return np.sign(weight)\n",
        "\n",
        "class ApplyReg(Regularisation):\n",
        "    def __init__(self, reg_function, network, weight=0):\n",
        "        self.reg_function = reg_function\n",
        "        super().__init__(network, weight)\n",
        "\n",
        "    def do_reg(self):\n",
        "        if self.reg_function == 'L2':\n",
        "            return L2_regularisation(self.network).Apply_L2()\n",
        "        if self.reg_function == 'L1':\n",
        "            return L1_regularisation(self.network).Apply_L1()\n",
        "        if self.reg_function == 'L2_d':\n",
        "            return L2_regularisation(self.network).Apply_L2_grad(self.weight)\n",
        "        if self.reg_function == 'L1_d':\n",
        "            return L1_regularisation(self.network).Apply_L1_grad(self.weight)\n",
        "\n",
        "\n",
        "class CalculateAllLoss:\n",
        "  def __init__(self, X_train, y_predicted,network, y_train, primary_loss, weight_decay=0, regularisation_fn=None):\n",
        "    self.y_predicted = y_predicted\n",
        "    self.y_true = y_train\n",
        "    self.network = network\n",
        "    self.X_train = X_train\n",
        "    self.loss_value = primary_loss\n",
        "    self.weight_decay = weight_decay\n",
        "    self.regularisation_fn= regularisation_fn\n",
        "    self.calc_accuracy_loss()\n",
        "\n",
        "\n",
        "  def overall_loss(self):\n",
        "    \"\"\"\n",
        "    Calculates the total loss of the network.\n",
        "    - Total loss value.\n",
        "    \"\"\"\n",
        "\n",
        "    total_loss = self.loss_value\n",
        "\n",
        "    if self.weight_decay > 0 and self.regularisation_fn:\n",
        "        regularized_val = ApplyReg(self.regularisation_fn, self.network).do_reg()\n",
        "        print(f\"Reg value: {regularized_val}\")\n",
        "        total_loss += self.weight_decay * regularized_val\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def calc_accuracy_loss(self):\n",
        "    \"\"\"\n",
        "    Computes the accuracy and loss for a given neural network.\n",
        "    \"\"\"\n",
        "\n",
        "    total_loss = self.loss_value\n",
        "\n",
        "    if self.weight_decay > 0 and self.regularisation_fn:\n",
        "        regularized_val = ApplyReg(self.regularisation_fn, self.network).do_reg()\n",
        "        print(f\"Reg value: {regularized_val}\")\n",
        "        total_loss += self.weight_decay * regularized_val\n",
        "\n",
        "\n",
        "    assert self.X_train.shape[1] == self.y_true.shape[1], \"Mismatch in batch size between inputs and labels\"\n",
        "\n",
        "\n",
        "    batch_size = self.X_train.shape[1]\n",
        "    correct_predictions = np.sum(np.argmax(self.y_predicted, axis=0) == np.argmax(self.y_true, axis=0))\n",
        "\n",
        "    accuracy = correct_predictions / batch_size\n",
        "\n",
        "    return accuracy , total_loss\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}