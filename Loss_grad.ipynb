{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "702941a3-fcf8-4294-9fdc-a6335b776556",
      "metadata": {
        "id": "702941a3-fcf8-4294-9fdc-a6335b776556"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class CalLoss:\n",
        "    def __init__(self, y, y_pred):\n",
        "        self.y = y\n",
        "        self.y_predicted = y_pred\n",
        "        if y.shape != y_pred.shape:\n",
        "            raise ValueError(f\"Shape mismatch: y shape is {self.y.shape}, y_predicted shape is {self.y_predicted.shape}\")\n",
        "\n",
        "class CrossEntropy(CalLoss):\n",
        "    def give_celoss(self):\n",
        "        epsilon = 1e-8\n",
        "        return -np.mean(self.y * np.log(self.y_predicted + epsilon))\n",
        "\n",
        "    def Give_cegrad(self):\n",
        "        epsilon = 1e-8\n",
        "        grad = -self.y / (self.y_predicted + epsilon)\n",
        "        return grad\n",
        "\n",
        "class SquaredError(CalLoss):\n",
        "    def give_seloss(self):\n",
        "        return np.mean((self.y - self.y_predicted) ** 2)\n",
        "\n",
        "    def Give_segrad(self):\n",
        "        grad = -2 * (self.y - self.y_predicted)\n",
        "        return np.clip(grad, -1, 1)\n",
        "\n",
        "class callloss(CalLoss):\n",
        "    def __init__(self, loss_function, y, y_pred):\n",
        "        self.loss_function = loss_function.lower()\n",
        "        super().__init__(y, y_pred)\n",
        "\n",
        "    def give_loss(self):\n",
        "        if self.loss_function == 'ce':\n",
        "            return CrossEntropy(self.y, self.y_predicted).give_celoss()\n",
        "        elif self.loss_function == 'se':\n",
        "            return SquaredError(self.y, self.y_predicted).give_seloss()\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown loss function: {self.loss_function}\")\n",
        "\n",
        "    def give_gradloss(self):\n",
        "        if self.loss_function == 'ce':\n",
        "            return CrossEntropy(self.y, self.y_predicted).Give_cegrad()\n",
        "        elif self.loss_function == 'se':\n",
        "            return SquaredError(self.y, self.y_predicted).Give_segrad()\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown loss function: {self.loss_function}\")\n",
        "\n",
        "\n",
        "class CalculateAllLoss:\n",
        "  def __init__(self, X_train, y_predicted,network, y_train, primary_loss, weight_decay=0, regularisation_fn=None):\n",
        "    self.y_predicted = y_predicted\n",
        "    self.y_true = y_train\n",
        "    self.network = network\n",
        "    self.X_train = X_train\n",
        "    self.loss_value = primary_loss\n",
        "    self.weight_decay = weight_decay\n",
        "    self.regularisation_fn= regularisation_fn\n",
        "    self.calc_accuracy_loss()\n",
        "\n",
        "\n",
        "  def overall_loss(self):\n",
        "    \"\"\"\n",
        "    Calculates the total loss of the network.\n",
        "    - Total loss value.\n",
        "    \"\"\"\n",
        "\n",
        "    total_loss = self.loss_value\n",
        "\n",
        "    if self.weight_decay > 0 and self.regularisation_fn:\n",
        "        regularized_val = ApplyReg(self.regularisation_fn, self.network).do_reg()\n",
        "        print(f\"Reg value: {regularized_val}\")\n",
        "        total_loss += self.weight_decay * regularized_val\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def calc_accuracy_loss(self):\n",
        "    \"\"\"\n",
        "    Computes the accuracy and loss for a given neural network.\n",
        "    \"\"\"\n",
        "\n",
        "    total_loss = self.loss_value\n",
        "\n",
        "    if self.weight_decay > 0 and self.regularisation_fn:\n",
        "        regularized_val = ApplyReg(self.regularisation_fn, self.network).do_reg()\n",
        "        print(f\"Reg value: {regularized_val}\")\n",
        "        total_loss += self.weight_decay * regularized_val\n",
        "\n",
        "\n",
        "    assert self.X_train.shape[1] == self.y_true.shape[1], \"Mismatch in batch size between inputs and labels\"\n",
        "\n",
        "\n",
        "    batch_size = self.X_train.shape[1]\n",
        "    correct_predictions = np.sum(np.argmax(self.y_predicted, axis=0) == np.argmax(self.y_true, axis=0))\n",
        "\n",
        "    accuracy = correct_predictions / batch_size\n",
        "\n",
        "    return accuracy , total_loss\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}