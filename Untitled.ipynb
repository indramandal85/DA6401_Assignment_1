{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "EuDCYeTFOWhL"
      },
      "id": "EuDCYeTFOWhL",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([[8,8,1],[7,9,1],[6,10,0],[5,5,0]], columns=['cgpa', 'profile_score', 'placed'])"
      ],
      "metadata": {
        "id": "fJ8rJlerOYGB"
      },
      "id": "fJ8rJlerOYGB",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['cgpa', 'profile_score']].values[0].reshape(2,1) # Shape(no of features, no. of training example)\n",
        "y = df[['placed']].values[0][0]"
      ],
      "metadata": {
        "id": "9724OEXSOX35"
      },
      "id": "9724OEXSOX35",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# This function calculates sigmoid activation function\n",
        "class sigmoid:\n",
        "\n",
        "    def __init__(self,m):\n",
        "        self.m = m\n",
        "        self.use_sigmoid()\n",
        "\n",
        "    def use_sigmoid(self):\n",
        "        sig = np.where(self.m >= 0,1/(1 - np.exp(-self.m)),np.exp(self.m)/(np.exp(-self.m) - 1))\n",
        "        return sig\n",
        "        #if self.m >= 0:\n",
        "            #return 1/(1 - np.exp(-self.m))\n",
        "        #else:\n",
        "            #return np.exp(self.m)/(np.exp(-self.m) - 1)\n",
        "\n",
        "\n",
        "# This function calculates tanh activation function\n",
        "class tanh:\n",
        "\n",
        "    def __init__(self,m):\n",
        "        self.m = m\n",
        "        self.use_tanh()\n",
        "\n",
        "    def use_tanh(self):\n",
        "        z = (np.exp(self.m) - np.exp(-self.m))/(np.exp(self.m) + np.exp(-self.m))\n",
        "        return z\n",
        "\n",
        "\n",
        "\n",
        "# This function calculates relu activation function\n",
        "class relu:\n",
        "\n",
        "    def __init__(self, m):\n",
        "        self.m = m\n",
        "        self.use_relu()\n",
        "\n",
        "    def use_relu(self):\n",
        "        if np.all(self.m > 0):\n",
        "            return self.m\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "\n",
        "\n",
        "# This function calculates softmax activation function\n",
        "class softmax:\n",
        "\n",
        "    def __init__(self, m):\n",
        "        self.m = m\n",
        "        self.use_softmax()\n",
        "\n",
        "    def use_softmax(self):\n",
        "        x = np.copy(self.m)\n",
        "        max_exp = np.max(x)\n",
        "\n",
        "        x = np.exp(x - max_exp)\n",
        "        x = x / np.sum(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# This function call different activation function\n",
        "class apply_activation:\n",
        "\n",
        "    def __init__(self, activation_function, value):\n",
        "        self.activation_function = activation_function.lower()\n",
        "        self.value = value\n",
        "        self.do_activation()\n",
        "\n",
        "\n",
        "    def do_activation(self):\n",
        "        if self.activation_function == 'sigmoid':\n",
        "            return sigmoid(self.value).use_sigmoid()\n",
        "        elif self.activation_function == 'relu':\n",
        "            return relu(self.value).use_relu()\n",
        "        elif self.activation_function == 'tanh':\n",
        "            return tanh(self.value).use_tanh()\n",
        "        elif self.activation_function == 'softmax':\n",
        "            return softmax(self.value).use_softmax()\n",
        "\n",
        "\n",
        "\n",
        "class sigmoid_derv:\n",
        "\n",
        "    def __init__(self,m):\n",
        "        self.m = m\n",
        "        self.sigmoid_d()\n",
        "\n",
        "    def sigmoid_d(self):\n",
        "        sig_d = np.where(self.m >= 0,1/(1 - np.exp(-self.m)),np.exp(self.m)/(np.exp(-self.m) - 1))\n",
        "        return sig_d * (1 - sig_d)\n",
        "\n",
        "\n",
        "\n",
        "class relu_derv:\n",
        "\n",
        "    def __init__(self,m):\n",
        "        self.m = m\n",
        "        self.relu_d()\n",
        "\n",
        "    def relu_d(self):\n",
        "        if self.m > 0:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "\n",
        "\n",
        "class tanh_derv:\n",
        "\n",
        "    def __init__(self,m):\n",
        "        self.m = m\n",
        "        self.tanh_d()\n",
        "\n",
        "    def tanh_d(self):\n",
        "        z = (np.exp(self.m) - np.exp(-self.m))/(np.exp(self.m) + np.exp(-self.m))\n",
        "        return (1 - (z)**2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class apply_activation_derivative:\n",
        "\n",
        "    def __init__(self,activation_function, value):\n",
        "        self.activation_function = activation_function.lower()\n",
        "        self.value = value\n",
        "        self.do_activation_derivative()\n",
        "\n",
        "    def do_activation_derivative(self):\n",
        "        if self.activation_function == 'sigmoid':\n",
        "            return sigmoid_derv(self.value).sigmoid_d()\n",
        "        elif self.activation_function == 'relu':\n",
        "            return relu_derv(self.value).relu_d()\n",
        "        elif self.activation_function == 'tanh':\n",
        "            return tanh_derv(self.value).tanh_d()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "01ZCcJdxviK6"
      },
      "id": "01ZCcJdxviK6",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class crossentropy:\n",
        "\n",
        "    def __init__(self, y, y_predicted):\n",
        "        self.y = y\n",
        "        self.y_predicted = y_predicted\n",
        "        self.give_celoss()\n",
        "\n",
        "    def give_celoss(self):\n",
        "        threshold = 10**(-8)\n",
        "        res = np.sum(y * (-np.log(self.y_predicted)))\n",
        "        return res\n",
        "\n",
        "class squarderror:\n",
        "\n",
        "    def __init__(self, y, y_predicted):\n",
        "        self.y = y\n",
        "        self.y_predicted = y_predicted\n",
        "        self.give_seloss()\n",
        "\n",
        "    def give_seloss(self):\n",
        "        res = np.square(self.y - self.y_predicted)\n",
        "        return np.sum(res)\n",
        "\n",
        "\n",
        "class callloss:\n",
        "\n",
        "    def __init__(self,loss_function, value1, value2):\n",
        "        self.loss_function = loss_function.lower()\n",
        "        self.value1 = value1\n",
        "        self.value2 = value2\n",
        "        self.give_loss()\n",
        "\n",
        "    def give_loss(self):\n",
        "        if self.loss_function == 'ce':\n",
        "            return crossentropy(self.value1, self.value2).give_celoss()\n",
        "        if self.loss_function == 'se':\n",
        "            return squarderror(self.value1, self.value2).give_seloss()\n",
        "\n",
        "class crossentropy_grad:\n",
        "\n",
        "    def __init__(self,y ,y_predicted):\n",
        "        self.y = y\n",
        "        self.y_predicted = y_predicted\n",
        "        self.Give_cegrad()\n",
        "\n",
        "    def Give_cegrad(self):\n",
        "        None\n",
        "\n",
        "\n",
        "class squarederror_grad:\n",
        "\n",
        "    def __init__(self,y , y_predicted):\n",
        "        self.y = y\n",
        "        self.y_predicted = y_predicted\n",
        "        self.Give_segrad()\n",
        "\n",
        "    def Give_segrad(self):\n",
        "        res = -np.sum(y - y_predicted)\n",
        "        return res\n",
        "\n",
        "class call_lossgrad:\n",
        "\n",
        "    def __init__(self,loss_function, value1, value2):\n",
        "        self.loss_function = loss_function.lower()\n",
        "        self.value1 = value1\n",
        "        self.value2 = value2\n",
        "        self.give_gradloss()\n",
        "\n",
        "    def give_gradloss(self):\n",
        "        if self.loss_function == 'ce':\n",
        "            return crossentropy_grad(self.value1, self.value2).Give_cegrad()\n",
        "        if self.loss_function == 'se':\n",
        "            return squarederror_grad(self.value1, self.value2).Give_segrad()"
      ],
      "metadata": {
        "id": "wZobAAjyjTVB"
      },
      "id": "wZobAAjyjTVB",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "895d572d-2ffd-466a-a260-e57859a6449e",
      "metadata": {
        "id": "895d572d-2ffd-466a-a260-e57859a6449e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Initilize:\n",
        "\n",
        "    def __init__(self, i_size, o_size, method = \"Xavier_U\"):\n",
        "        self.i_size = i_size\n",
        "        self.o_size = o_size\n",
        "        self.w, self.b = self.Init_weight(method)\n",
        "\n",
        "    def Init_weight(self, init_method):\n",
        "\n",
        "\n",
        "        if init_method == \"Xavier_N\":\n",
        "          np.random.seed(0)\n",
        "          a = np.sqrt(1 / self.i_size)\n",
        "          w = np.random.randn(self.i_size,self.o_size)*a\n",
        "\n",
        "        elif init_method == \"Xavier_U\":\n",
        "          np.random.seed(0)\n",
        "          a = np.sqrt(6 / (self.o_size + self.i_size))\n",
        "          w = np.random.uniform((-a), a,( self.i_size, self.o_size))\n",
        "\n",
        "        elif init_method == \"He_N\":\n",
        "          np.random.seed(0)\n",
        "          a = np.sqrt(2 / self.i_size)\n",
        "          w = np.random.randn(self.i_size, self.o_size)*a\n",
        "\n",
        "        elif init_method == \"He_U\":\n",
        "          np.random.seed(0)\n",
        "          a = np.sqrt(6 / self.i_size)\n",
        "          w = np.random.uniform(-a, a, (self.i_size, self.o_size))\n",
        "\n",
        "        elif init_method == \"Random\":\n",
        "          np.random.seed(0)\n",
        "          w = np.random.randn(self.i_size, self.o_size)*0.01\n",
        "\n",
        "        b = np.zeros((self.o_size,1))\n",
        "\n",
        "        return w, b\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Weight_bias:\n",
        "  def __init__(self, layer_dimension, activation_fn, method):\n",
        "    self.n = layer_dimension\n",
        "    self.activation_fn = activation_fn\n",
        "    self.method = method\n",
        "\n",
        "  def Init_network(self, layer_dimension):\n",
        "    self.n = layer_dimension\n",
        "    self.network = {}\n",
        "\n",
        "    for i in range(1, len(self.n)):\n",
        "      self.network[\"w\" + str(i)] = Initilize(self.n[i-1], self.n[i], self.method).Init_weight(self.method)[0]\n",
        "      self.network[\"b\" + str(i)] = Initilize(self.n[i-1], self.n[i], self.method).Init_weight(self.method)[1]\n",
        "      self.network [\"h\"+ str(i)] = str(self.activation_fn[i-1])\n",
        "      self.network [\"Hidden_layer \"+ str(i)] = self.n[i]\n",
        "\n",
        "    return self.network\n",
        "\n",
        "\n",
        "\n",
        "class Pre_Feedforward:\n",
        "\n",
        "  def __init__(self, Prev_layer_H, w, b, activation_fn):\n",
        "    self.Prev_layer_H= Prev_layer_H\n",
        "    self.w = w\n",
        "    self.b = b\n",
        "    self.activation_fn = activation_fn\n",
        "    self.Preactivation_cal()\n",
        "\n",
        "\n",
        "  def Preactivation_cal(self):\n",
        "    self.cache = {}\n",
        "\n",
        "    A = np.dot(self.w.T, self.Prev_layer_H) + self.b\n",
        "    H = apply_activation(self.activation_fn, A).do_activation()\n",
        "    cache = (self.Prev_layer_H, A)\n",
        "    #self.cache[\"Input\"] = self.Prev_layer_H\n",
        "    #self.cache[\"Pre_act\"] = H\n",
        "    return cache , H\n",
        "\n",
        "class Feedforward:\n",
        "\n",
        "  def __init__(self,X_train, layer_dimension, activation_fn, method):\n",
        "    self.X_train = X_train\n",
        "    self.n = layer_dimension\n",
        "    self.activation_fn = activation_fn\n",
        "    self.method = method\n",
        "\n",
        "\n",
        "  def Forward_prop(self):\n",
        "    network = Weight_bias(self.n, self.activation_fn,self.method).Init_network(self.n)\n",
        "    H = self.X_train\n",
        "    L = len(network) // 4\n",
        "    Inter_layers = {}\n",
        "\n",
        "    for i in range(1,L+1):\n",
        "      Prev_layer_H = H\n",
        "\n",
        "      w_l = network[\"w\"+  str(i)]\n",
        "      b_l = network[\"b\"+  str(i)]\n",
        "      Act_fn_l = network[\"h\" + str(i)]\n",
        "\n",
        "      cache, H = Pre_Feedforward(Prev_layer_H, w_l,b_l,Act_fn_l).Preactivation_cal()\n",
        "\n",
        "\n",
        "      #A = np.dot(w_l.T, Prev_layer_H) + b_l\n",
        "      #H = apply_activation(Act_fn_l, A).do_activation()\n",
        "\n",
        "      Inter_layers[\"h\" + str(i-1)] = cache[0]\n",
        "      Inter_layers[\"a\" + str(i)] = cache[1]\n",
        "      #cache.append((Prev_layer_H, A))\n",
        "\n",
        "      #cache , New_H = Pre_Feedforward(Prev_layer_H, w_l, b_l, Act_fn_l).Preactivation_cal()\n",
        "      #cache.appand()\n",
        "\n",
        "    return cache,Inter_layers,network , H"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MhJrZkPpp7Zv"
      },
      "id": "MhJrZkPpp7Zv",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PFRmUzwVmaO",
        "outputId": "8a6c1e06-3706-4e6e-b1e4-682b6343409d"
      },
      "id": "3PFRmUzwVmaO",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8],\n",
              "       [8]])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Feedforward(X,[2,3,1],['sigmoid','sigmoid','sigmoid','softmax'],\"Xavier_U\").Forward_prop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV7gYASA0m8t",
        "outputId": "3923109d-bcb8-4da6-ca10-e205c416760c"
      },
      "id": "NV7gYASA0m8t",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[1.23999836],\n",
              "         [1.09616172],\n",
              "         [1.01296675]]),\n",
              "  array([[0.98103753]])),\n",
              " {'h0': array([[8],\n",
              "         [8]]),\n",
              "  'a1': array([[1.64223325],\n",
              "         [2.43353861],\n",
              "         [4.35825011]]),\n",
              "  'h1': array([[1.23999836],\n",
              "         [1.09616172],\n",
              "         [1.01296675]]),\n",
              "  'a2': array([[0.98103753]])},\n",
              " {'w1': array([[ 0.10694503,  0.47145628,  0.22514328],\n",
              "         [ 0.09833413, -0.16726395,  0.31963799]]),\n",
              "  'b1': array([[0.],\n",
              "         [0.],\n",
              "         [0.]]),\n",
              "  'h1': 'sigmoid',\n",
              "  'Hidden_layer 1': 3,\n",
              "  'w2': array([[0.11956818],\n",
              "         [0.52710415],\n",
              "         [0.25171784]]),\n",
              "  'b2': array([[0.]]),\n",
              "  'h2': 'sigmoid',\n",
              "  'Hidden_layer 2': 1},\n",
              " array([[1.5998001]]))"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "2064d83c-b27e-46e6-bef2-c24d9faf70ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2064d83c-b27e-46e6-bef2-c24d9faf70ff",
        "outputId": "910ebdd9-ad32-4083-f488-ee00db9a3ce2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 1.0184761 ,  0.23103087,  0.56507464,  1.29378029,  1.07823511],\n",
              "        [-0.56423165,  0.5485338 , -0.08738612, -0.05959343,  0.23705916],\n",
              "        [ 0.08316359,  0.8396252 ,  0.43938534,  0.0702491 ,  0.25626456]]),\n",
              " array([[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "Initilize(3,5,\"Xavier_N\").Init_weight(\"Xavier_N\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [relu,relu,sigmoid]\n",
        "print(x[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIOXHXcuRF9-",
        "outputId": "4119227a-98db-40b1-f35f-bfeab8f8f932"
      },
      "id": "AIOXHXcuRF9-",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.relu'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Weight_bias([4,2,3,1],['relu','relu','sigmoid'],\"Xavier_N\").Init_network([4,2,3,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NKWIZNDdN7u",
        "outputId": "ef624cc7-d424-420a-ec56-3591e88468f2"
      },
      "id": "4NKWIZNDdN7u",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'w1': array([[ 0.88202617,  0.2000786 ],\n",
              "        [ 0.48936899,  1.1204466 ],\n",
              "        [ 0.933779  , -0.48863894],\n",
              "        [ 0.47504421, -0.0756786 ]]),\n",
              " 'b1': array([[0.],\n",
              "        [0.]]),\n",
              " 'h1': 'relu',\n",
              " 'Hidden_layer 1': 2,\n",
              " 'w2': array([[ 1.24737338,  0.28295388,  0.69207227],\n",
              "        [ 1.58455078,  1.32056292, -0.69103982]]),\n",
              " 'b2': array([[0.],\n",
              "        [0.],\n",
              "        [0.]]),\n",
              " 'h2': 'relu',\n",
              " 'Hidden_layer 2': 3,\n",
              " 'w3': array([[1.0184761 ],\n",
              "        [0.23103087],\n",
              "        [0.56507464]]),\n",
              " 'b3': array([[0.]]),\n",
              " 'h3': 'sigmoid',\n",
              " 'Hidden_layer 3': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eAhzWxfwt_ub"
      },
      "id": "eAhzWxfwt_ub",
      "execution_count": 11,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}