{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "892a6714-fd7b-4cbd-ac63-f272a4453a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# This function calculates sigmoid activation function\n",
    "class sigmoid:\n",
    "\n",
    "    def __init__(self,m):\n",
    "        self.m = m\n",
    "        self.use_sigmoid()\n",
    "\n",
    "    def use_sigmoid(self):\n",
    "        if self.m >= 0:\n",
    "            return 1/(1 - np.exp(-self.m))\n",
    "        else:\n",
    "            return np.exp(self.m)/(np.exp(-self.m) - 1)\n",
    "\n",
    "\n",
    "# This function calculates tanh activation functio\n",
    "class tanh:\n",
    "\n",
    "    def __init__(self,m):\n",
    "        self.m = m\n",
    "        self.use_tanh()\n",
    "\n",
    "    def use_tanh(self):\n",
    "        z = (np.exp(self.m) - np.exp(-self.m))/(np.exp(self.m) + np.exp(-self.m))\n",
    "        return z\n",
    "\n",
    "\n",
    "\n",
    "# This function calculates relu activation function\n",
    "class relu:\n",
    "\n",
    "    def __init__(self, m):\n",
    "        self.m = m\n",
    "        self.use_relu()\n",
    "\n",
    "    def use_relu(self):\n",
    "        if self.m >= 0:\n",
    "            return self.m\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "\n",
    "class softmax:\n",
    "\n",
    "    def __init__(self, m):\n",
    "        self.m = m\n",
    "        self.use_softmax()\n",
    "\n",
    "    def use_softmax(self):\n",
    "        x = np.copy(self.m)\n",
    "        max_exp = np.max(x)\n",
    "\n",
    "        x = np.exp(x - max_exp)\n",
    "        x = x / np.sum(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# This function call different activation function\n",
    "class apply_activation:\n",
    "\n",
    "    def __init__(self, activation_function, value):\n",
    "        self.activation_function = activation_function.lower()\n",
    "        self.value = value\n",
    "        self.do_activation()\n",
    "\n",
    "\n",
    "\n",
    "    def do_activation(self):\n",
    "        if self.activation_function == 'sigmoid':\n",
    "            return sigmoid(self.value).use_sigmoid()\n",
    "        elif self.activation_function == 'relu':\n",
    "            return relu(self.value).use_relu()\n",
    "        elif self.activation_function == 'tanh':\n",
    "            return tanh(self.value).use_tanh()\n",
    "        elif self.activation_function == 'softmax':\n",
    "            return softmax(self.value).use_softmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d6416e-6592-418e-adb8-4ef3388a16cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
